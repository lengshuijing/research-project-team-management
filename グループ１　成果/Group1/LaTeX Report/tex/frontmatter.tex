\title{Beyond Zero-Shot: A Hierarchical Approach To Multi-Agent Collaboration For Improved LLM Accuracy}

\author{
    \bf Giovanpaolo Vrenna \\ \texttt{Giovanpaolo.vrenna@keio.jp} \\
    \and
    \bf Shigeki Noguchi \\ \texttt{noguchi\_shigeki@keio.jp} \\
    \and
    \bf Naoki Watson \\ \texttt{naokiwatson@keio.jp} \\
    \and
    \bf Keita Fujie \\ \texttt{fk77663@keio.jp} \\
}

\date{}
\maketitle
\onehalfspacing

\begin{abstract}
    When Large Language Model agents engage in debate, they collectively enhance their intelligence. This study explores the impact of hierarchical communication structures on multi-agent debate systems, introducing two distinct hierarchical topologies along with a method for their implementation. Our results indicate that these structures improve reasoning performance, achieving approximately 20\% higher accuracy compared to zero-shot agents. Additionally, we conducted a comparative analysis of shallow and deep hierarchical topologies. While our findings do not explicitly reveal a performance difference, our analysis of conversation history suggests that deeper hierarchical structures introduce greater redundancy in the reasoning process, which may, in turn, enhance self-correction
\end{abstract}
